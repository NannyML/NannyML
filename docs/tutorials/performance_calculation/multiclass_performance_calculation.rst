.. _multiclass-performance-calculation:

================================================================
Monitoring Realized Performance for Multiclass Classification
================================================================

Why Monitor Realized Performance
===================================

The realized performance of a machine learning model is the actual performance of the model's outputs compared with 
the :term:`target` values. It is typically a good proxy for the business impact of the model.
A significant drop in performance normally means a lot of the value generated by the model is at risk,
so close monitoring and quick resolution of issues are essential.

This guide shows how to use NannyML to calculate the :term:`Realized Performance` of a model.
Target values need to be available in both the reference and analysis data.
All monitoring metrics available by NannyML for monitoring will be shown.

.. note::
    The performance monitoring process requires no missing values in the target data on the reference dataset. However,
    the analysis data can contain missing values. The entries with missing values will simply be ignored when
    calculating the performance results. If there are so many missing values that the available data are below the
    :ref:`minimum-chunk-size` then the performance results are omitted from the resulting visualizations because they are
    too noisy to be reliable.

=====================

Just The Code
-------------

.. code-block:: python

    >>> import pandas as pd
    >>> import nannyml as nml
    >>> from IPython.display import display
    >>> reference, analysis, analysis_targets = nml.datasets.load_synthetic_multiclass_classification_dataset()
    >>> display(reference.head(3))

    >>> data = pd.concat([
    ...     reference,
    ...     analysis.set_index('identifier').join(analysis_targets.set_index('identifier'), on='identifier', rsuffix='_r')
    >>> ], ignore_index=True).reset_index(drop=True)
    >>> display(data.loc[data['partition'] == 'analysis'].head(3))

    >>> metadata = nml.extract_metadata(
    ...     reference,
    ...     model_name='credit_card_segment',
    ...     model_type='classification_multiclass',
    ...     exclude_columns=['identifier']
    >>> )
    >>> metadata.target_column_name = 'y_true'
    >>> display(metadata.is_complete())

    >>> performance_calculator = nml.PerformanceCalculator(
    ...     model_metadata=metadata,
    ...     metrics=['roc_auc', 'f1'],
    ...     chunk_size=6000
    >>> ).fit(reference_data=reference)

    >>> realized_performance = performance_calculator.calculate(data)

    >>> display(realized_performance.data.head(3))

    >>> for metric in performance_calculator.metrics:
    ...     figure = realized_performance.plot(kind='performance', metric=metric)
    ...     figure.show()



Walkthrough
----------------------------------------------


Prepare the data
~~~~~~~~~~~~~~~~

For simplicity the guide is based on a synthetic dataset where the monitored model predicts
which type of credit card product new customers should be assigned to. You can :ref:`learn more about this dataset<dataset-synthetic-multiclass>`.

The dataset is split into ``reference`` and ``analysis`` dataframes, which correspond to ``reference`` and ``analysis`` periods of
the monitored data. To understand more about what they are read :ref:`data periods<data-drift-periods>`. 

The ``analysis_targets`` dataframe contains the target results of the analysis period. This is kept separate because it is
not used during :ref:`performance estimation.<performance-estimation>`

.. code-block:: python

    >>> import pandas as pd
    >>> import nannyml as nml
    >>> from IPython.display import display
    >>> reference, analysis, analysis_targets = nml.datasets.load_synthetic_multiclass_classification_dataset()
    >>> display(reference.head(3))

+----+---------------+------------------------+--------------------------+---------------+-----------------------+-----------------+---------------+-------------+--------------+---------------------+-----------------------------+--------------------------------+------------------------------+--------------+---------------+
|    | acq_channel   |   app_behavioral_score |   requested_credit_limit | app_channel   |   credit_bureau_score |   stated_income | is_customer   | partition   |   identifier | timestamp           |   y_pred_proba_prepaid_card |   y_pred_proba_highstreet_card |   y_pred_proba_upmarket_card | y_pred       | y_true        |
+====+===============+========================+==========================+===============+=======================+=================+===============+=============+==============+=====================+=============================+================================+==============================+==============+===============+
|  0 | Partner3      |               1.80823  |                      350 | web           |                   309 |           15000 | True          | reference   |        60000 | 2020-05-02 02:01:30 |                        0.97 |                           0.03 |                         0    | prepaid_card | prepaid_card  |
+----+---------------+------------------------+--------------------------+---------------+-----------------------+-----------------+---------------+-------------+--------------+---------------------+-----------------------------+--------------------------------+------------------------------+--------------+---------------+
|  1 | Partner2      |               4.38257  |                      500 | mobile        |                   418 |           23000 | True          | reference   |        60001 | 2020-05-02 02:03:33 |                        0.87 |                           0.13 |                         0    | prepaid_card | prepaid_card  |
+----+---------------+------------------------+--------------------------+---------------+-----------------------+-----------------+---------------+-------------+--------------+---------------------+-----------------------------+--------------------------------+------------------------------+--------------+---------------+
|  2 | Partner2      |              -0.787575 |                      400 | web           |                   507 |           24000 | False         | reference   |        60002 | 2020-05-02 02:04:49 |                        0.47 |                           0.35 |                         0.18 | prepaid_card | upmarket_card |
+----+---------------+------------------------+--------------------------+---------------+-----------------------+-----------------+---------------+-------------+--------------+---------------------+-----------------------------+--------------------------------+------------------------------+--------------+---------------+


The realized performance will be calculated on the combination of both reference and analysis data. The analysis target
values are joined on the analysis frame by the ``identifier`` column.

.. code-block:: python

    >>> data = pd.concat([
    ...     reference,
    ...     analysis.set_index('identifier').join(analysis_targets.set_index('identifier'), on='identifier', rsuffix='_r')
    >>> ], ignore_index=True).reset_index(drop=True)
    >>> display(data.loc[data['partition'] == 'analysis'].head(3))

+-------+---------------+------------------------+--------------------------+---------------+-----------------------+-----------------+---------------+-------------+--------------+---------------------+-----------------------------+--------------------------------+------------------------------+-----------------+-----------------+
|       | acq_channel   |   app_behavioral_score |   requested_credit_limit | app_channel   |   credit_bureau_score |   stated_income | is_customer   | partition   |   identifier | timestamp           |   y_pred_proba_prepaid_card |   y_pred_proba_highstreet_card |   y_pred_proba_upmarket_card | y_pred          | y_true          |
+=======+===============+========================+==========================+===============+=======================+=================+===============+=============+==============+=====================+=============================+================================+==============================+=================+=================+
| 60000 | Organic       |              -1.64376  |                      300 | store         |                   439 |           15000 | False         | analysis    |          nan | 2020-09-01 03:10:01 |                        0.39 |                           0.35 |                         0.26 | prepaid_card    | upmarket_card   |
+-------+---------------+------------------------+--------------------------+---------------+-----------------------+-----------------+---------------+-------------+--------------+---------------------+-----------------------------+--------------------------------+------------------------------+-----------------+-----------------+
| 60001 | Partner2      |              -0.148435 |                      450 | store         |                   565 |           18000 | False         | analysis    |          nan | 2020-09-01 03:10:53 |                        0.72 |                           0.01 |                         0.27 | prepaid_card    | prepaid_card    |
+-------+---------------+------------------------+--------------------------+---------------+-----------------------+-----------------+---------------+-------------+--------------+---------------------+-----------------------------+--------------------------------+------------------------------+-----------------+-----------------+
| 60002 | Partner1      |              -2.28461  |                      600 | mobile        |                   691 |           28000 | False         | analysis    |          nan | 2020-09-01 03:11:39 |                        0.03 |                           0.75 |                         0.22 | highstreet_card | highstreet_card |
+-------+---------------+------------------------+--------------------------+---------------+-----------------------+-----------------+---------------+-------------+--------------+---------------------+-----------------------------+--------------------------------+------------------------------+-----------------+-----------------+

One of the first steps in using NannyML is providing metadata information about the model we are monitoring.
Some information is infered automatically and we provide the rest.

.. code-block:: python

    >>> metadata = nml.extract_metadata(
    ...     reference,
    ...     model_name='credit_card_segment',
    ...     model_type='classification_multiclass',
    ...     exclude_columns=['identifier']
    >>> )
    >>> metadata.target_column_name = 'y_true'
    >>> display(metadata.is_complete())
    (True, [])


We see that the metadata are complete. Full information on how to extract metadata can be found in the :ref:`providing metadata guide<import-data>`.

Fit calculator and calculate
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

In the next step a :class:`~nannyml.performance_calculation.calculator.PerformanceCalculator` is created using the previously
extracted :class:`~nannyml.metadata.base.ModelMetadata`, a list of metrics and an optional :ref:`chunking<chunking>` specification.

The list of metrics specifies which performance metrics of the monitored model will be calculated. 
The following metrics are currently supported:

- ``roc_auc`` - one vs. the rest, macro averaged
- ``f1`` - macro averaged
- ``precision`` - macro averaged
- ``recall`` - macro averaged
- ``specificity`` - macro averaged
- ``accuracy``

For more information on metrics, check the :mod:`~nannyml.performance_calculation.metrics` module.

The new :class:`~nannyml.performance_calculation.calculator.PerformanceCalculator` is then fitted using the
:meth:`~nannyml.performance_calculation.calculator.PerformanceCalculator.fit` method on the ``reference`` data.

.. code-block:: python

    >>> performance_calculator = nml.PerformanceCalculator(
    ...     model_metadata=metadata,
    ...     metrics=['roc_auc', 'f1'],
    ...     chunk_size=6000
    >>> ).fit(reference_data=reference)

The fitted :class:`~nannyml.performance_calculation.calculator.PerformanceCalculator` can then be used to calculate
realized performance metrics on all data which has target values available.

.. code-block:: python

    >>> realized_performance = performance_calculator.calculate(data)


View the results
~~~~~~~~~~~~~~~~

NannyML can output a dataframe that contains all the results.

Apart from chunking and chunk and partition-related data, the results data have the a set of columns for each
calculated metric. When taking ``roc_auc`` as an example:

 - ``roc_auc`` - The value of the metric for a specific chunk.
 - ``roc_auc_thresholds`` - A tuple containing the lower and upper thresholds. Crossing them will raise an alert on significant
   metric change. The thresholds are calculated based on the realized performance metric of the monitored model on chunks in
   the ``reference`` period. The thresholds are 3 standard deviations away from the mean performance calculated on
   ``reference`` chunks.
 - ``roc_auc_alert`` - Flag indicating potentially significant performance change. ``True`` if realized performance crosses
   upper or lower threshold.

.. code-block:: python

    >>> display(realized_performance.data.head(3))

+----+---------------+---------------+-------------+---------------------+---------------------+-------------+------------------------+-----------+-----------------------------------------+-----------------+----------+-----------------------------------------+------------+
|    | key           |   start_index |   end_index | start_date          | end_date            | partition   |   targets_missing_rate |   roc_auc | roc_auc_thresholds                      | roc_auc_alert   |       f1 | f1_thresholds                           | f1_alert   |
+====+===============+===============+=============+=====================+=====================+=============+========================+===========+=========================================+=================+==========+=========================================+============+
|  0 | [0:5999]      |             0 |        5999 | 2020-05-02 02:01:30 | 2020-05-14 12:25:35 | reference   |                      0 |  0.90476  | (0.900902260737325, 0.9135156728918074) | False           | 0.750532 | (0.741253919065521, 0.7649438592270994) | False      |
+----+---------------+---------------+-------------+---------------------+---------------------+-------------+------------------------+-----------+-----------------------------------------+-----------------+----------+-----------------------------------------+------------+
|  1 | [6000:11999]  |          6000 |       11999 | 2020-05-14 12:29:25 | 2020-05-26 18:27:42 | reference   |                      0 |  0.905917 | (0.900902260737325, 0.9135156728918074) | False           | 0.751148 | (0.741253919065521, 0.7649438592270994) | False      |
+----+---------------+---------------+-------------+---------------------+---------------------+-------------+------------------------+-----------+-----------------------------------------+-----------------+----------+-----------------------------------------+------------+
|  2 | [12000:17999] |         12000 |       17999 | 2020-05-26 18:31:06 | 2020-06-07 19:55:45 | reference   |                      0 |  0.909329 | (0.900902260737325, 0.9135156728918074) | False           | 0.75714  | (0.741253919065521, 0.7649438592270994) | False      |
+----+---------------+---------------+-------------+---------------------+---------------------+-------------+------------------------+-----------+-----------------------------------------+-----------------+----------+-----------------------------------------+------------+


The results can be plotted for vizual inspection:

.. code-block:: python

    >>> for metric in performance_calculator.metrics:
    ...     figure = realized_performance.plot(kind='performance', metric=metric)
    ...     figure.show()

.. image:: /_static/tutorial-perf-guide-mc-F1.svg

.. image:: /_static/tutorial-perf-guide-mc-ROC_AUC.svg


Insights
=======================

After reviewing the performance calculation results, we should be able to clearly see how the model is performing against
the targets, according to whatever metrics we wish to track.



What Next
=======================

If we decide further investigation is needed, the :ref:`Data Drift<data-drift>` functionality can help us to see
what feature changes may be contributing to any performance changes.

It is also wise to check whether the model's performance is satisfactory
according to business requirements. This is an ad-hoc investigation that is not covered by NannyML.
